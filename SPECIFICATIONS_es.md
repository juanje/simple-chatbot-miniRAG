# Simple Chatbot - Especificaciones TÃ©cnicas

## ğŸ“‹ Resumen del Proyecto

**Simple Chatbot** es una aplicaciÃ³n de lÃ­nea de comandos que implementa un chatbot conversacional utilizando LangChain y Ollama. El proyecto estÃ¡ diseÃ±ado con fines educativos y para demostrar las mejores prÃ¡cticas en el desarrollo de aplicaciones Python modernas con LLMs locales.

## ğŸ¯ Objetivos

- **Educativo**: Demostrar la implementaciÃ³n de un chatbot usando tecnologÃ­as modernas
- **Modular**: Arquitectura limpia con separaciÃ³n de responsabilidades
- **FÃ¡cil de usar**: Interfaz CLI intuitiva con comandos especiales
- **Configurable**: ParÃ¡metros ajustables para diferentes casos de uso
- **Robusto**: Manejo de errores y validaciones completas

## ğŸ—ï¸ Arquitectura

### Estructura del Proyecto

```
simple-chatbot/
â”œâ”€â”€ src/simple_chatbot/
â”‚   â”œâ”€â”€ __init__.py          # MÃ³dulo principal
â”‚   â”œâ”€â”€ chatbot.py           # LÃ³gica core del chatbot
â”‚   â”œâ”€â”€ cli.py               # Interfaz de lÃ­nea de comandos
â”‚   â”œâ”€â”€ config.py            # ConfiguraciÃ³n centralizada
â”‚   â”œâ”€â”€ llm_client.py        # Cliente para Ollama
â”‚   â””â”€â”€ memory.py            # GestiÃ³n de memoria conversacional
â”œâ”€â”€ tests/                   # Tests unitarios
â”œâ”€â”€ pyproject.toml          # ConfiguraciÃ³n del proyecto
â”œâ”€â”€ README.md               # DocumentaciÃ³n de usuario
â””â”€â”€ SPECIFICATIONS.md       # Este archivo
```

### Componentes Principales

#### 1. **SimpleChatbot** (`chatbot.py`)
- **Responsabilidad**: OrquestaciÃ³n de la conversaciÃ³n
- **Funcionalidades**:
  - GestiÃ³n del flujo de conversaciÃ³n
  - IntegraciÃ³n con memoria y cliente LLM
  - Formateo de prompts
  - EstadÃ­sticas de conversaciÃ³n
  - Health checks

#### 2. **CLI Interface** (`cli.py`)
- **Responsabilidad**: Interfaz de usuario
- **Funcionalidades**:
  - Interfaz Rich con paneles y colores
  - NavegaciÃ³n con historial de comandos (â†‘â†“)
  - Comandos especiales con prefijo `/`
  - Atajos de teclado (Ctrl+L para limpiar)
  - Manejo de errores user-friendly

#### 3. **OllamaClient** (`llm_client.py`)
- **Responsabilidad**: ComunicaciÃ³n con Ollama
- **Funcionalidades**:
  - ConexiÃ³n a Ollama via HTTP
  - ValidaciÃ³n de modelos disponibles
  - ConfiguraciÃ³n de parÃ¡metros de generaciÃ³n
  - Manejo de errores de conexiÃ³n

#### 4. **ConversationMemory** (`memory.py`)
- **Responsabilidad**: GestiÃ³n de memoria conversacional
- **Funcionalidades**:
  - LÃ­mite configurable de mensajes
  - Formateo para prompts
  - EstadÃ­sticas de conversaciÃ³n
  - Reset de historial

#### 5. **ChatbotConfig** (`config.py`)
- **Responsabilidad**: ConfiguraciÃ³n centralizada
- **Funcionalidades**:
  - ParÃ¡metros del modelo (temperatura, max_tokens)
  - URLs de conexiÃ³n
  - LÃ­mites de memoria
  - Prompt del sistema

## ğŸ› ï¸ Stack TecnolÃ³gico

### Core Dependencies
- **Python**: 3.10+ (type hints modernos)
- **LangChain**: Framework para aplicaciones LLM
- **LangChain-Ollama**: IntegraciÃ³n especÃ­fica con Ollama
- **Pydantic**: ValidaciÃ³n de datos y configuraciÃ³n

### CLI & UX
- **Rich**: Interfaz de terminal avanzada
- **Click**: Framework para CLI
- **prompt-toolkit**: Input avanzado con historial

### Development Tools
- **uv**: GestiÃ³n de dependencias y entornos virtuales
- **ruff**: Linting y formateo de cÃ³digo
- **pytest**: Framework de testing
- **mypy**: Type checking estÃ¡tico

## ğŸ“‹ Funcionalidades Implementadas

### Funcionalidades Core
- âœ… **ConversaciÃ³n bÃ¡sica**: Chat interactivo con LLMs locales
- âœ… **Memoria conversacional**: Mantiene contexto de la conversaciÃ³n
- âœ… **ConfiguraciÃ³n flexible**: MÃºltiples parÃ¡metros ajustables
- âœ… **MÃºltiples modelos**: Soporte para cualquier modelo de Ollama

### Comandos Especiales
- âœ… `/quit`, `/exit`, `/bye`: Terminar conversaciÃ³n
- âœ… `/reset`: Limpiar historial de conversaciÃ³n
- âœ… `/stats`: Mostrar estadÃ­sticas de la conversaciÃ³n
- âœ… `/history`: Ver historial completo
- âœ… `/help`: Mostrar ayuda

### CaracterÃ­sticas UX
- âœ… **Interfaz Rica**: Paneles coloreados y formato mejorado
- âœ… **Historial de comandos**: NavegaciÃ³n con â†‘â†“
- âœ… **Shortcuts**: Ctrl+L para limpiar pantalla
- âœ… **Loading indicators**: Spinners durante procesamiento
- âœ… **Manejo de errores**: Mensajes informativos

### Opciones de CLI
- âœ… `--model`: SelecciÃ³n de modelo Ollama
- âœ… `--temperature`: Control de creatividad (0.0-1.0)
- âœ… `--max-tokens`: LÃ­mite de tokens de respuesta
- âœ… `--long-responses`: Modo respuestas largas (4000 tokens)
- âœ… `--ollama-url`: URL personalizada de Ollama
- âœ… `--memory-limit`: LÃ­mite de mensajes en memoria
- âœ… `--debug`: Logging detallado

## ğŸ”§ ConfiguraciÃ³n

### Variables de Entorno
```bash
OLLAMA_BASE_URL=http://localhost:11434
MODEL_NAME=llama2
TEMPERATURE=0.7
MAX_TOKENS=2000
CONVERSATION_MEMORY_LIMIT=10
```

### ConfiguraciÃ³n ProgramÃ¡tica
```python
config = ChatbotConfig(
    ollama_base_url="http://localhost:11434",
    model_name="mistral",
    temperature=0.5,
    max_tokens=3000,
    conversation_memory_limit=15
)
```

## ğŸš€ InstalaciÃ³n y Uso

### InstalaciÃ³n Local
```bash
# Clonar y entrar al directorio
git clone <repo-url>
cd simple-chatbot

# Instalar dependencias
uv sync

# Verificar instalaciÃ³n
uv run chatbot --help
```

### InstalaciÃ³n Global
```bash
# OpciÃ³n 1: pipx (recomendado)
pipx install .

# OpciÃ³n 2: uv tool
uv tool install .
```

### Uso BÃ¡sico
```bash
# Ejecutar con configuraciÃ³n por defecto
uv run chatbot

# Usar modelo especÃ­fico
uv run chatbot --model mistral --temperature 0.5

# Modo debug para desarrollo
uv run chatbot --debug
```

## ğŸ§ª Testing

### Estructura de Tests
```
tests/
â”œâ”€â”€ test_chatbot.py     # Tests del componente principal
â”œâ”€â”€ test_config.py      # Tests de configuraciÃ³n
â””â”€â”€ test_memory.py      # Tests de memoria conversacional
```

### Ejecutar Tests
```bash
# Tests completos
uv run pytest

# Con coverage
uv run pytest --cov=src/simple_chatbot
```

## ğŸ“Š MÃ©tricas y EstadÃ­sticas

El chatbot proporciona las siguientes mÃ©tricas:
- **Total messages**: NÃºmero total de mensajes intercambiados
- **User messages**: Mensajes del usuario
- **Bot messages**: Respuestas del bot
- **Average message length**: Longitud promedio de mensajes
- **Conversation duration**: DuraciÃ³n de la sesiÃ³n

## ğŸ” Seguridad y Consideraciones

### Seguridad
- **Datos locales**: Todos los datos permanecen en el sistema local
- **Sin telemetrÃ­a**: No se envÃ­an datos a servicios externos
- **ValidaciÃ³n de entrada**: SanitizaciÃ³n bÃ¡sica de inputs

### Limitaciones
- **Dependencia de Ollama**: Requiere Ollama ejecutÃ¡ndose localmente
- **Memoria volÃ¡til**: El historial se pierde al cerrar la aplicaciÃ³n
- **Sin persistencia**: No hay almacenamiento permanente de conversaciones

## ğŸ“ˆ Posibles Mejoras Futuras

### Funcionalidades
- [ ] **Persistencia**: Guardar conversaciones en base de datos
- [ ] **MÃºltiples sesiones**: Gestionar varias conversaciones
- [ ] **Export/Import**: Exportar conversaciones a archivos
- [ ] **ConfiguraciÃ³n por archivo**: Archivos de configuraciÃ³n TOML/YAML
- [ ] **Plugins**: Sistema de extensiones

### TÃ©cnicas
- [ ] **Async/await**: Mejorar concurrencia
- [ ] **Streaming**: Respuestas en tiempo real
- [ ] **Rate limiting**: LÃ­mites de uso
- [ ] **Metrics**: MÃ©tricas avanzadas con Prometheus
- [ ] **Web UI**: Interfaz web opcional

## ğŸ¤ Contribuciones

### EstÃ¡ndares de CÃ³digo
- **Type hints**: Obligatorios en todas las funciones
- **Docstrings**: Google style para todas las funciones pÃºblicas
- **Ruff**: Linting y formateo automÃ¡tico
- **Tests**: Coverage mÃ­nimo del 90%

### Process de Desarrollo
1. **Fork** del repositorio
2. **Branch** para nueva funcionalidad
3. **Tests** para cualquier cambio
4. **PR** con descripciÃ³n detallada

## ğŸ“ Versionado

El proyecto sigue [Semantic Versioning](https://semver.org/):
- **MAJOR**: Cambios incompatibles en la API
- **MINOR**: Nuevas funcionalidades compatible
- **PATCH**: Bug fixes compatibles

**VersiÃ³n actual**: 0.1.0

---

## ğŸ“„ Licencia

Este proyecto estÃ¡ diseÃ±ado con fines educativos y de demostraciÃ³n.

**Autor**: Juanje Ojeda (juanje@redhat.com)
**Fecha**: Julio 2025